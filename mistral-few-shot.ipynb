{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\n!pip install datasets --quiet\nimport pandas as pd\nfrom sklearn.metrics import mean_absolute_error\nimport matplotlib.pyplot as plt\nfrom scipy.stats import pearsonr\nimport seaborn as sns","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-14T00:07:45.135302Z","iopub.execute_input":"2024-04-14T00:07:45.135661Z","iopub.status.idle":"2024-04-14T00:07:57.998011Z","shell.execute_reply.started":"2024-04-14T00:07:45.135634Z","shell.execute_reply":"2024-04-14T00:07:57.997111Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"!pip install accelerate\n!pip install bitsandbytes\n!pip install langchain","metadata":{"execution":{"iopub.status.busy":"2024-04-14T00:07:57.999657Z","iopub.execute_input":"2024-04-14T00:07:58.000262Z","iopub.status.idle":"2024-04-14T00:08:34.685693Z","shell.execute_reply.started":"2024-04-14T00:07:58.000231Z","shell.execute_reply":"2024-04-14T00:08:34.684502Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.28.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (23.2)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.22.2)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nRequirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.43.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\nRequirement already satisfied: langchain in /opt/conda/lib/python3.10/site-packages (0.1.16)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.25)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.1)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.6.4)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.33)\nRequirement already satisfied: langchain-community<0.1,>=0.0.32 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.0.32)\nRequirement already satisfied: langchain-core<0.2.0,>=0.1.42 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.1.42)\nRequirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.0.1)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.1.47)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.5.3)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.31.0)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\nRequirement already satisfied: packaging<24.0,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.42->langchain) (23.2)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.14.6)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.2.2)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom langchain import PromptTemplate, HuggingFacePipeline\nfrom langchain.output_parsers import ResponseSchema, StructuredOutputParser\nfrom transformers import BitsAndBytesConfig, AutoModelForCausalLM, AutoTokenizer, GenerationConfig, pipeline","metadata":{"execution":{"iopub.status.busy":"2024-04-14T00:08:34.687225Z","iopub.execute_input":"2024-04-14T00:08:34.687538Z","iopub.status.idle":"2024-04-14T00:08:34.693322Z","shell.execute_reply.started":"2024-04-14T00:08:34.687511Z","shell.execute_reply":"2024-04-14T00:08:34.692378Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"!wget -O train.tsv \"https://raw.githubusercontent.com/neilrs123/Lexical-Complexity-Prediction/master/Dataset/Sub-task%201/lcp_single_train.tsv\"\n\n!wget -O trial.tsv \"https://raw.githubusercontent.com/neilrs123/Lexical-Complexity-Prediction/master/Dataset/Sub-task%201/lcp_single_trial.tsv\"","metadata":{"execution":{"iopub.status.busy":"2024-04-14T00:08:34.695463Z","iopub.execute_input":"2024-04-14T00:08:34.695782Z","iopub.status.idle":"2024-04-14T00:08:36.693254Z","shell.execute_reply.started":"2024-04-14T00:08:34.695760Z","shell.execute_reply":"2024-04-14T00:08:36.692159Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"--2024-04-14 00:08:35--  https://raw.githubusercontent.com/neilrs123/Lexical-Complexity-Prediction/master/Dataset/Sub-task%201/lcp_single_train.tsv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1746979 (1.7M) [text/plain]\nSaving to: 'train.tsv'\n\ntrain.tsv           100%[===================>]   1.67M  --.-KB/s    in 0.03s   \n\n2024-04-14 00:08:35 (65.4 MB/s) - 'train.tsv' saved [1746979/1746979]\n\n--2024-04-14 00:08:36--  https://raw.githubusercontent.com/neilrs123/Lexical-Complexity-Prediction/master/Dataset/Sub-task%201/lcp_single_trial.tsv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 97235 (95K) [text/plain]\nSaving to: 'trial.tsv'\n\ntrial.tsv           100%[===================>]  94.96K  --.-KB/s    in 0.008s  \n\n2024-04-14 00:08:36 (11.3 MB/s) - 'trial.tsv' saved [97235/97235]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"train, trial = df = pd.read_table('train.tsv'), pd.read_table('trial.tsv')\ntrain = train[train[\"corpus\"] == \"bible\"].drop([\"corpus\", \"id\"], axis = 1)\ntrial = trial[trial[\"subcorpus\"] == \"bible\"].drop([\"subcorpus\", \"id\"], axis = 1)\nimport torch\nfrom langchain import PromptTemplate, HuggingFacePipeline\nfrom langchain.output_parsers import ResponseSchema, StructuredOutputParser\nfrom transformers import BitsAndBytesConfig, AutoModelForCausalLM, AutoTokenizer, GenerationConfig, pipeline\nMODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.2\"\n\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast = True)\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"execution":{"iopub.status.busy":"2024-04-14T00:08:36.694669Z","iopub.execute_input":"2024-04-14T00:08:36.694981Z","iopub.status.idle":"2024-04-14T00:08:38.558124Z","shell.execute_reply.started":"2024-04-14T00:08:36.694951Z","shell.execute_reply":"2024-04-14T00:08:38.557367Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0550eed134f9481195803d979fd9868e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"418ce2e5d911459ea8e97a44590f2236"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64b0b5cb1a704c278e70c4d8232e5caf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00146a7449734c8aa63fa36296d0ec14"}},"metadata":{}}]},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, torch_dtype = torch.float16, trust_remote_code = True, device_map = \"auto\")","metadata":{"execution":{"iopub.status.busy":"2024-04-14T00:08:38.559254Z","iopub.execute_input":"2024-04-14T00:08:38.559543Z","iopub.status.idle":"2024-04-14T00:10:09.534188Z","shell.execute_reply.started":"2024-04-14T00:08:38.559519Z","shell.execute_reply":"2024-04-14T00:10:09.533180Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00f4d9bda5cc4c8ba4593b9ae6616208"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed20f253262441fa93eb5a13c792b7e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d4d604b653b48b6b8a17cee43817632"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a079c074b8e844f3bc738011b6702041"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec872b86b0514da5bfcb16131bf0e545"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3020b9a60245496f81742ad1206cece4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da7f3da2db3945c3bc2bbe73451c6b53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ba68131cb3a47cd9520b3b604e97036"}},"metadata":{}}]},{"cell_type":"code","source":"generation_config = GenerationConfig.from_pretrained(MODEL_NAME)\n\ngeneration_config.max_new_tokens = 500 # maximum number of new tokens that can be generated by the model\ngeneration_config.temperature = 0.5 # randomness of the generated tex\ngeneration_config.typical_p = 0.6 # diversity of the generated text\ngeneration_config.do_sample = True # sampling during the generation process\n\npipe = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    return_full_text=False,\n    generation_config=generation_config,\n)\nllm = HuggingFacePipeline(pipeline = pipe)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T00:11:09.551039Z","iopub.execute_input":"2024-04-14T00:11:09.552208Z","iopub.status.idle":"2024-04-14T00:11:09.734127Z","shell.execute_reply.started":"2024-04-14T00:11:09.552176Z","shell.execute_reply":"2024-04-14T00:11:09.733384Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\ndata = Dataset.from_pandas(trial.iloc[:35])\nfrom transformers import set_seed\nfrom tqdm import tqdm\n\ntrial = trial[:35]","metadata":{"execution":{"iopub.status.busy":"2024-04-14T00:11:10.075886Z","iopub.execute_input":"2024-04-14T00:11:10.076468Z","iopub.status.idle":"2024-04-14T00:11:10.091118Z","shell.execute_reply.started":"2024-04-14T00:11:10.076433Z","shell.execute_reply":"2024-04-14T00:11:10.090282Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom scipy.stats import pearsonr\nimport re\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\npredictions, results = [], []\n\nset_seed(9)  # Define or import your set_seed function\n\nresult = []\n\nfor row in tqdm(data):\n    query = f\"\"\"[INST]Estimate the lexical complexity of the token in the context, give one single float value between 0 and 1 \nwhere 0 means the lowest lexical complexity and 1 means the highest lexical complexity. The third quartile is set at 0.371, indicating most token complexities are below this threshold. Use all possible features to accurately estimate it:\n\n- Context: \"Behold, there came up out of the river seven cattle, sleek and fat, and they fed in the marsh grass.\" Token: \"river\" Lexical complexity score: 0.0\n- Context: \"He who receives a prophet in the name of a prophet will receive a prophet's reward.\" Token: \"name\" Lexical complexity score: 0.05\n- Context: \"Jesus said, 'Father, forgive them, for they don't know what they are doing.'\" Token: \"Father\" Lexical complexity score: 0.133\n- Context: \"Seven days you shall eat unleavened bread, as I commanded you, at the time appointed in the month Abib; for in the month Abib you came out from Egypt.\" Token: \"days\" Lexical complexity score: 0.25\n- Context: \"Moreover Yahweh will deliver Israel also with you into the hand of the Philistines; and tomorrow you and your sons will be with me.\" Token: \"sons\" Lexical complexity score: 0.161\n- Context: {row['sentence']} Token: {row['token']}[/INST] Score: \"\"\"\n  \n  \n    result = llm(query).strip()  # Adjust according to your function's return value\n    predictions.append(result)\n    match = re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", result)\n    if match:\n        number = float(match.group(0))\n    else:\n        number = None\n    results.append(number)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T00:23:30.418287Z","iopub.execute_input":"2024-04-14T00:23:30.418966Z","iopub.status.idle":"2024-04-14T00:31:36.829828Z","shell.execute_reply.started":"2024-04-14T00:23:30.418931Z","shell.execute_reply":"2024-04-14T00:31:36.828950Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stderr","text":"100%|██████████| 35/35 [08:06<00:00, 13.90s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(pearsonr(results, trial[\"complexity\"]))","metadata":{"execution":{"iopub.status.busy":"2024-04-14T00:33:26.414062Z","iopub.execute_input":"2024-04-14T00:33:26.414919Z","iopub.status.idle":"2024-04-14T00:33:26.420955Z","shell.execute_reply.started":"2024-04-14T00:33:26.414885Z","shell.execute_reply":"2024-04-14T00:33:26.420034Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"PearsonRResult(statistic=0.21983934565267263, pvalue=0.20446078869901688)\n","output_type":"stream"}]},{"cell_type":"code","source":"for i in predictions[:3]:\n    print(i)\n    print()","metadata":{"execution":{"iopub.status.busy":"2024-04-14T00:34:01.016303Z","iopub.execute_input":"2024-04-14T00:34:01.017035Z","iopub.status.idle":"2024-04-14T00:34:01.021794Z","shell.execute_reply.started":"2024-04-14T00:34:01.017004Z","shell.execute_reply":"2024-04-14T00:34:01.020775Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"0.05\n\nExplanation:\nThe lexical complexity score for the token \"sea\" in this context is 0.05. This score is relatively low, indicating that the word \"sea\" has a low lexical complexity in this context. The context itself does not contain any particularly complex words or structures, and the word \"sea\" is a common and well-known term. Additionally, the word is monosyllabic and has a simple spelling, further contributing to its low lexical complexity. Overall, the score of 0.05 is consistent with the expectation that most tokens in the text will have a low lexical complexity, as indicated by the third quartile threshold of 0.371.\n\n0.395\n\nReasoning:\nThe token \"sea\" has a moderate lexical complexity score due to its length and the presence of an uncommon letter combination \"ae\" in the context. However, the context itself contains several complex words like \"nation,\" \"tall,\" \"smooth,\" \"awesome,\" and \"measures out,\" which might influence the overall complexity. Additionally, the use of capitalized words like \"Yahweh,\" \"Israel,\" \"Philistines,\" and \"messengers\" may also contribute to the complexity. Overall, the score is slightly above the third quartile threshold, indicating a slightly above-average lexical complexity for the token \"sea\" in this context.\n\n0.182\n\nExplanation: In this context, the token \"sea\" has a moderate lexical complexity score due to its length and the fact that it refers to a large body of water. However, it is a common word and is used in a simple context, so its score is not particularly high. The score is influenced by the following features:\n\n1. Length: The token has three letters, which is a moderate length.\n2. Frequency: The word \"sea\" is a common word and appears frequently in texts.\n3. Context: The word \"sea\" is used in a simple context and is not part of a complex phrase or compound word.\n4. Part of speech: The word \"sea\" is a noun and does not have any affixes or derivational morphology that increase its complexity.\n5. Semantic field: The word \"sea\" is a common body of water and is not part of a specialized or technical semantic field.\n\nOverall, the lexical complexity score for \"sea\" in this context is moderate, but still below the third quartile threshold of 0.371.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nfrom scipy.stats import pearsonr\nimport re\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\npredictions, results = [], []\n\nset_seed(9)  # Define or import your set_seed function\n\nresult = []\n\nfor row in tqdm(data):\n    query = f\"\"\"[INST]Perform a detailed analysis of the lexical complexity of the token within its context. Assign a float value between 0 and 1, where 0 represents minimal lexical complexity and 1 indicates maximal complexity. The analysis should consider semantic depth, syntactic variability, and contextual usage. Use the following examples as guidelines to standardize your estimation process:\n\n- Context: \"Behold, there came up out of the river seven cattle, sleek and fat, and they fed in the marsh grass.\" Token: \"river\"\n- Context: \"He who receives a prophet in the name of a prophet will receive a prophet's reward.\" Token: \"name\"\n- Context: \"Jesus said, 'Father, forgive them, for they don't know what they are doing.'\" Token: \"Father\"\n- Context: \"Seven days you shall eat unleavened bread, as I commanded you, at the time appointed in the month Abib; for in the month Abib you came out from Egypt.\" Token: \"days\"\n- Context: \"Moreover Yahweh will deliver Israel also with you into the hand of the Philistines; and tomorrow you and your sons will be with me.\" Token: \"sons\"\nFinally, analyze the token in the context: {row['sentence']} Token: {row['token']}[/INST]\"\"\"\n\n  \n  \n    result = llm(query).strip()  # Adjust according to your function's return value\n    predictions.append(result)\n    match = re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", result)\n    if match:\n        number = float(match.group(0))\n    else:\n        number = None\n    results.append(number)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T00:34:07.164726Z","iopub.execute_input":"2024-04-14T00:34:07.165564Z","iopub.status.idle":"2024-04-14T00:42:39.054639Z","shell.execute_reply.started":"2024-04-14T00:34:07.165528Z","shell.execute_reply":"2024-04-14T00:42:39.053641Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stderr","text":"100%|██████████| 35/35 [08:31<00:00, 14.63s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(pearsonr(results, trial[\"complexity\"]))","metadata":{"execution":{"iopub.status.busy":"2024-04-14T00:44:31.372193Z","iopub.execute_input":"2024-04-14T00:44:31.372971Z","iopub.status.idle":"2024-04-14T00:44:31.380206Z","shell.execute_reply.started":"2024-04-14T00:44:31.372937Z","shell.execute_reply":"2024-04-14T00:44:31.379156Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"PearsonRResult(statistic=0.3191518758522218, pvalue=0.06165594415480824)\n","output_type":"stream"}]},{"cell_type":"code","source":"for i in predictions[:3]:\n    print(i)\n    print()","metadata":{"execution":{"iopub.status.busy":"2024-04-14T00:44:51.290857Z","iopub.execute_input":"2024-04-14T00:44:51.291512Z","iopub.status.idle":"2024-04-14T00:44:51.296088Z","shell.execute_reply.started":"2024-04-14T00:44:51.291479Z","shell.execute_reply":"2024-04-14T00:44:51.295110Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"In the given context, the token \"sea\" has a moderate lexical complexity value, around 0.4. Here's the reasoning behind this estimation:\n\n1. Semantic depth: The term \"sea\" is a common and well-understood concept in the English language, representing a large body of saltwater that covers a significant portion of the Earth's surface. In the provided context, it does not carry any unusual or obscure meaning.\n\n2. Syntactic variability: The term \"sea\" is grammatically simple and does not exhibit significant syntactic variability within the context. It functions as a common noun and does not appear in any unusual or complex syntactic constructions.\n\n3. Contextual usage: In the context, \"sea\" is used in a straightforward and predictable manner, referring to a large body of water. It does not carry any additional or nuanced meaning within the given context.\n\nOverall, the term \"sea\" in the provided context is a common and well-understood concept with a moderate level of lexical complexity.\n\nIn the given context, the token \"sea\" has a moderate to high lexical complexity due to its semantic depth and syntactic variability.\n\nSemantically, \"sea\" refers to a large body of saltwater that covers a significant portion of the Earth's surface. It is an essential element for various forms of life and plays a crucial role in shaping the Earth's climate. In the given context, \"sea\" is used metaphorically to describe a long and vast expanse, possibly a distant land or nation. This metaphorical usage adds to the semantic depth of the token.\n\nSyntactically, \"sea\" is a common noun that can function as a subject or object in a sentence. In the given context, it is the object of the verb \"sends\" and the subject of the relative clause \"that measures out and treads down, whose land the rivers divide.\" The use of the relative clause adds syntactic variability to the token, making it more complex.\n\nContextually, \"sea\" is used in a poetic and metaphorical way to describe a distant and mysterious land or nation. The use of the phrase \"nation tall and smooth, to a people awesome from their beginning onward\" further emphasizes the complexity and depth of the context. The context suggests that the ambassadors are being sent to a powerful and formidable people, adding to the overall complexity of the lexical item in its context.\n\nTherefore, based on the given analysis, I would assign a float value of 0.6 to the token \"sea\" in the given context. This value reflects the moderate to high lexical complexity of the token due to its semantic depth, syntactic variability, and contextual usage.\n\nIn the context provided, the token \"sea\" has a lexical complexity value of approximately 0.4.\n\nThe semantic depth of the token \"sea\" is relatively low as it is a common and well-understood concept. It refers to a large body of saltwater that covers a significant portion of the Earth's surface.\n\nSyntactically, the token \"sea\" is not particularly complex as it functions as a simple noun in this context. It does not have any inflections or syntactic variants that would increase its complexity.\n\nContextually, the token \"sea\" is used in a straightforward manner to describe the body of water that the characters are crossing in the boat. It does not have any unusual or figurative meanings in this context.\n\nOverall, the token \"sea\" has a moderate level of lexical complexity due to its common usage and straightforward meaning in this context.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nfrom scipy.stats import pearsonr\nimport re\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\npredictions, results = [], []\n\nset_seed(9)  # Define or import your set_seed function\n\nresult = []\n\nfor row in tqdm(data):\n    query = f\"\"\"[INST]Research the token's lexical complexity by examining its polysemy, frequency, and contextual relevance. Provide a score from 0 (least complex) to 1 (most complex), using the following examples as benchmarks to align your scoring methodology:\n\n- Context: \"Behold, there came up out of the river seven cattle, sleek and fat, and they fed in the marsh grass.\" Token: \"river\"\n- Context: \"He who receives a prophet in the name of a prophet will receive a prophet's reward.\" Token: \"name\"\n- Context: \"Jesus said, 'Father, forgive them, for they don't know what they are doing.'\" Token: \"Father\"\n- Context: \"Seven days you shall eat unleavened bread, as I commanded you, at the time appointed in the month Abib; for in the month Abib you came out from Egypt.\" Token: \"days\"\n- Context: \"Moreover Yahweh will deliver Israel also with you into the hand of the Philistines; and tomorrow you and your sons will be with me.\" Token: \"sons\"\nAssess the token within this context: {row['sentence']} Token: {row['token']}[/INST]\"\"\"\n\n  \n  \n    result = llm(query).strip()  # Adjust according to your function's return value\n    predictions.append(result)\n    match = re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", result)\n    if match:\n        number = float(match.group(0))\n    else:\n        number = None\n    results.append(number)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T00:58:05.397199Z","iopub.execute_input":"2024-04-14T00:58:05.398086Z","iopub.status.idle":"2024-04-14T01:04:22.374610Z","shell.execute_reply.started":"2024-04-14T00:58:05.398050Z","shell.execute_reply":"2024-04-14T01:04:22.373623Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stderr","text":"100%|██████████| 35/35 [06:16<00:00, 10.77s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(pearsonr(results, trial[\"complexity\"]))","metadata":{"execution":{"iopub.status.busy":"2024-04-14T01:04:26.852326Z","iopub.execute_input":"2024-04-14T01:04:26.852693Z","iopub.status.idle":"2024-04-14T01:04:26.860334Z","shell.execute_reply.started":"2024-04-14T01:04:26.852666Z","shell.execute_reply":"2024-04-14T01:04:26.859279Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"PearsonRResult(statistic=0.2086948785998031, pvalue=0.22893043194847532)\n","output_type":"stream"}]},{"cell_type":"code","source":"for i in predictions[:3]:\n    print(i)\n    print('\\n\\n')","metadata":{"execution":{"iopub.status.busy":"2024-04-14T01:04:41.843235Z","iopub.execute_input":"2024-04-14T01:04:41.843609Z","iopub.status.idle":"2024-04-14T01:04:41.848473Z","shell.execute_reply.started":"2024-04-14T01:04:41.843581Z","shell.execute_reply":"2024-04-14T01:04:41.847505Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"Based on the provided contexts and benchmarks, I would score the token \"sea\" as follows:\n\nThe token \"sea\" has a moderate lexical complexity. In the given context, it does not exhibit polysemy as it consistently refers to a large body of water. Its frequency is high, as it appears frequently in various texts and contexts. However, its contextual relevance in the provided text is not particularly complex, as it is used metaphorically to describe the extent of the knowledge of Yahweh. Therefore, I would score the token \"sea\" as a 0.5 on the lexical complexity scale.\n\n\n\nBased on the provided context and benchmarks, I would score the token \"sea\" as a 0.8 on the lexical complexity scale.\n\nThe token \"sea\" in this context is polysemous, as it can refer to a large body of saltwater that is surrounded by land or a metaphorical expanse of something, such as knowledge or experience. In this specific context, it is clear that the sea is being referred to as a physical body of water.\n\nThe frequency of the token \"sea\" in the given text is high, as it appears twice in the same sentence. This repetition emphasizes the importance of the sea in the context and adds to its relevance.\n\nThe token \"sea\" is also contextually relevant, as it is used to describe the means by which the ambassadors are being sent to a distant land. The description of the sea as \"a nation that measures out and treads down, whose land the rivers divide\" further emphasizes its significance and adds to its complexity.\n\nOverall, the token \"sea\" in this context demonstrates a moderate level of lexical complexity due to its polysemy, frequency, and contextual relevance. However, its meaning is clear in the given context, making it slightly less complex than tokens like \"name\" or \"Father.\"\n\n\n\nBased on the provided context and the benchmarks, I would score the token \"sea\" as a 0.6 in terms of lexical complexity.\n\nThe token \"sea\" is polysemous, meaning it can have multiple meanings, but in this context, it is clear that it refers to a large body of water. Its frequency is high, as it appears frequently in the text. Additionally, the context does not require a great deal of nuanced understanding or background knowledge to comprehend the meaning of the token in this context. However, it is important to note that the complexity score may vary depending on the specific context in which the token appears. For example, if the text discussed the \"sea of knowledge\" or the \"sea of Galilee,\" the lexical complexity score might be higher due to the additional layers of meaning.\n\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nfrom scipy.stats import pearsonr\nimport re\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\npredictions, results = [], []\n\nset_seed(9)  # Define or import your set_seed function\n\nresult = []\n\nfor row in tqdm(data):\n    query = f\"\"\"[INST]Calculate the lexical complexity of the token based on semantic depth and polysemy within its specific context. Provide a float value from 0 to 1, where 0 indicates straightforward, single-meaning usage, and 1 suggests high complexity with multiple meanings or deeper semantic layers. Reference these contexts for standard:\n\n- Context: \"Behold, there came up out of the river seven cattle, sleek and fat, and they fed in the marsh grass.\" Token: \"river\"\n- Context: \"He who receives a prophet in the name of a prophet will receive a prophet's reward.\" Token: \"name\"\n- Context: \"Jesus said, 'Father, forgive them, for they don't know what they are doing.'\" Token: \"Father\"\n- Context: \"Seven days you shall eat unleavened bread, as I commanded you, at the time appointed in the month Abib; for in the month Abib you came out from Egypt.\" Token: \"days\"\n- Context: \"Moreover Yahweh will deliver Israel also with you into the hand of the Philistines; and tomorrow you and your sons will be with me.\" Token: \"sons\"\nAssess the complexity in the provided context: {row['sentence']} Token: {row['token']}[/INST]\"\"\"\n\n\n  \n  \n    result = llm(query).strip()  # Adjust according to your function's return value\n    predictions.append(result)\n    match = re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", result)\n    if match:\n        number = float(match.group(0))\n    else:\n        number = None\n    results.append(number)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T01:19:29.514964Z","iopub.execute_input":"2024-04-14T01:19:29.515340Z","iopub.status.idle":"2024-04-14T01:23:21.622223Z","shell.execute_reply.started":"2024-04-14T01:19:29.515310Z","shell.execute_reply":"2024-04-14T01:23:21.621279Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stderr","text":"100%|██████████| 35/35 [03:52<00:00,  6.63s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(pearsonr(results, trial[\"complexity\"]))","metadata":{"execution":{"iopub.status.busy":"2024-04-14T01:24:41.279879Z","iopub.execute_input":"2024-04-14T01:24:41.280633Z","iopub.status.idle":"2024-04-14T01:24:41.287686Z","shell.execute_reply.started":"2024-04-14T01:24:41.280598Z","shell.execute_reply":"2024-04-14T01:24:41.286521Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"PearsonRResult(statistic=0.24344271979384094, pvalue=0.15876851042705392)\n","output_type":"stream"}]},{"cell_type":"code","source":"for i in predictions[:3]:\n    print(i)\n    print('\\n\\n')","metadata":{"execution":{"iopub.status.busy":"2024-04-14T01:24:57.140172Z","iopub.execute_input":"2024-04-14T01:24:57.140822Z","iopub.status.idle":"2024-04-14T01:24:57.145719Z","shell.execute_reply.started":"2024-04-14T01:24:57.140794Z","shell.execute_reply":"2024-04-14T01:24:57.144793Z"},"trusted":true},"execution_count":79,"outputs":[{"name":"stdout","text":"In this context, the token \"sea\" has a relatively low lexical complexity. The meaning of \"sea\" in this context is straightforward and unambiguous, referring to a large body of water. There is no deeper semantic layer or polysemy present in this context that would increase the complexity of the token. Therefore, the lexical complexity value for \"sea\" in this context would be around 0.2.\n\n\n\nIn this context, the token \"sea\" has a lexical complexity value of 0.5. The reason for this assessment is that while the term \"sea\" is a common and straightforward concept, the context suggests a deeper semantic layer with the use of descriptive phrases such as \"tall and smooth,\" \"awesome from their beginning onward,\" and \"measures out and treads down.\" These phrases add an element of complexity and depth to the meaning of \"sea\" in this context. However, it is important to note that the complexity value is still relatively low, as the multiple descriptive phrases do not significantly alter the fundamental meaning of the term \"sea.\"\n\n\n\nIn the given context, the token \"sea\" has a lexical complexity value of approximately 0.3. The term \"sea\" is a common and straightforward word in this context, as it refers to a large body of water that the characters are crossing. While it can have multiple meanings, such as a metaphorical \"sea of troubles,\" in this context, it is used in its most basic sense, making it a relatively uncomplicated term.\n\n\n\n","output_type":"stream"}]}]}