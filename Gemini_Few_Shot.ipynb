{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHpME7Mh_yK2"
      },
      "outputs": [],
      "source": [
        "!pip -q install google-generativeai==0.3.0\n",
        "!pip -q install google-ai-generativelanguage==0.4.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "# !pip install datasets --quiet\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import pearsonr\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "3PKthQ5y_zLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O train.tsv \"https://raw.githubusercontent.com/neilrs123/Lexical-Complexity-Prediction/master/Dataset/Sub-task%201/lcp_single_train.tsv\"\n",
        "\n",
        "!wget -O trial.tsv \"https://raw.githubusercontent.com/neilrs123/Lexical-Complexity-Prediction/master/Dataset/Sub-task%201/lcp_single_trial.tsv\""
      ],
      "metadata": {
        "id": "QA0JAv0J_61r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, trial = df = pd.read_table('train.tsv'), pd.read_table('trial.tsv')\n",
        "\n",
        "train = train[train[\"corpus\"] == \"bible\"].drop([\"corpus\", \"id\"], axis = 1)\n",
        "trial = trial[trial[\"subcorpus\"] == \"bible\"].drop([\"subcorpus\", \"id\"], axis = 1)"
      ],
      "metadata": {
        "id": "nSlhbi3q_72S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "uykOnezU_89K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "GOOGLE_AI_STUDIO = userdata.get('key')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_AI_STUDIO)"
      ],
      "metadata": {
        "id": "1jbdAlII_-Bu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "    print(m.name)\n",
        "    print(m.supported_generation_methods)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "6br1kd1v_-5v",
        "outputId": "2e0ec97b-8199-4671-9d66-10346f9d8c4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/chat-bison-001\n",
            "['generateMessage', 'countMessageTokens']\n",
            "models/text-bison-001\n",
            "['generateText', 'countTextTokens', 'createTunedTextModel']\n",
            "models/embedding-gecko-001\n",
            "['embedText', 'countTextTokens']\n",
            "models/gemini-1.0-pro\n",
            "['generateContent', 'countTokens']\n",
            "models/gemini-1.0-pro-001\n",
            "['generateContent', 'countTokens', 'createTunedModel']\n",
            "models/gemini-1.0-pro-latest\n",
            "['generateContent', 'countTokens']\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "['generateContent', 'countTokens']\n",
            "models/gemini-pro\n",
            "['generateContent', 'countTokens']\n",
            "models/gemini-pro-vision\n",
            "['generateContent', 'countTokens']\n",
            "models/embedding-001\n",
            "['embedContent']\n",
            "models/aqa\n",
            "['generateAnswer']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets --quiet\n",
        "from datasets import Dataset\n",
        "\n",
        "data = Dataset.from_pandas(trial[:35])"
      ],
      "metadata": {
        "id": "TMS3k-_t__5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the model\n",
        "generation_config = {\n",
        "  \"temperature\": 0.0,\n",
        "  \"top_p\": 0.6,\n",
        "  \"top_k\": 1,\n",
        "  \"max_output_tokens\": 100,\n",
        "}\n",
        "\n",
        "\n",
        "safe = [\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_DANGEROUS\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "    ]\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.0-pro-latest\",\n",
        "                              generation_config=generation_config, safety_settings = safe)\n",
        "\n",
        "result = []\n",
        "\n",
        "for row in tqdm(data):\n",
        "\n",
        "  prompt_parts = [\n",
        "    \"Sentence: Behold, there came up out of the river seven cattle, sleek and fat, and they fed in the marsh grass. \"\\\n",
        "    \"Token: river \"\\\n",
        "    \"Lexical complexity score of token: 0.0 \"\\\n",
        "    \"Sentence: He who receives a prophet in the name of a prophet will receive a prophet's reward. \"\\\n",
        "    \"Token: name \"\\\n",
        "    \"Lexical complexity score of token: 0.04999999999999999 \"\\\n",
        "    \"Sentence: Jesus said, 'Father, forgive them, for they don't know what they are doing.' \"\\\n",
        "    \"Token: Father \"\\\n",
        "    \"Lexical complexity score of token: 0.13333333333333336 \"\\\n",
        "    \"Sentence: Seven days you shall eat unleavened bread, as I commanded you, at the time appointed in the month Abib; for in the month Abib you came out from Egypt. \"\\\n",
        "    \"Token: days \"\\\n",
        "    \"Lexical complexity score of token: 0.25 \"\\\n",
        "    \"Sentence: Moreover Yahweh will deliver Israel also with you into the hand of the Philistines; and tomorrow you and your sons will be with me. \"\\\n",
        "    \"Token: sons \"\\\n",
        "    \"Lexical complexity score of token: 0.1607142857142857  \"\\\n",
        "    f\"Sentence: {row['sentence']} \" \\\n",
        "    f\"Token: {row['token']} \"\\\n",
        "    \"Lexical complexity score of token: \"\\\n",
        "  ]\n",
        "  response = model.generate_content(prompt_parts)\n",
        "  # print(response.text)\n",
        "  result.append(float(response.text))\n",
        "\n",
        "  # here most of the output are 0.16, repeating the last example label\n",
        "\n",
        "  # Correlation 0.285"
      ],
      "metadata": {
        "id": "CG9XkHnxDOzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr\n",
        "\n",
        "print(pearsonr(result, trial[:35][\"complexity\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYKmD51AAE6d",
        "outputId": "0a2a1e12-37d6-4ff2-efe4-8de378c1ffc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PearsonRResult(statistic=0.2847779276396676, pvalue=0.09729378929608574)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the model\n",
        "generation_config = {\n",
        "  \"temperature\": 0.0,\n",
        "  \"top_p\": 0.6,\n",
        "  \"top_k\": 1,\n",
        "  \"max_output_tokens\": 100,\n",
        "}\n",
        "\n",
        "\n",
        "safe = [\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_DANGEROUS\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "    ]\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.0-pro-latest\",\n",
        "                              generation_config=generation_config, safety_settings = safe)\n",
        "\n",
        "result = []\n",
        "\n",
        "for row in tqdm(data):\n",
        "\n",
        "  prompt_parts = [\n",
        "    \"Sentence: Behold, there came up out of the river seven cattle, sleek and fat, and they fed in the marsh grass. \"\\\n",
        "    \"Token: river \"\\\n",
        "    \"Lexical complexity score of token: 0.0 \"\\\n",
        "    \"Sentence: He who receives a prophet in the name of a prophet will receive a prophet's reward. \"\\\n",
        "    \"Token: name \"\\\n",
        "    \"Lexical complexity score of token: 0.04999999999999999 \"\\\n",
        "    \"Sentence: Jesus said, 'Father, forgive them, for they don't know what they are doing.' \"\\\n",
        "    \"Token: Father \"\\\n",
        "    \"Lexical complexity score of token: 0.13333333333333336 \"\\\n",
        "    \"Sentence: Seven days you shall eat unleavened bread, as I commanded you, at the time appointed in the month Abib; for in the month Abib you came out from Egypt. \"\\\n",
        "    \"Token: days \"\\\n",
        "    \"Lexical complexity score of token: 0.25 \"\\\n",
        "    \"Sentence: Moreover Yahweh will deliver Israel also with you into the hand of the Philistines; and tomorrow you and your sons will be with me. \"\\\n",
        "    \"Token: sons \"\\\n",
        "    \"Lexical complexity score of token: 0.1607142857142857  \"\\\n",
        "    f\"Sentence: {row['sentence']} \" \\\n",
        "    f\"Token: {row['token']} \"\\\n",
        "    \"Lexical complexity score of token: \"\\\n",
        "\n",
        "    \"Learn from these examples and use all features you need, output one single number\"\n",
        "  ]\n",
        "  response = model.generate_content(prompt_parts)\n",
        "  # print(response.text)\n",
        "  result.append(float(response.text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "N9kG0jkTABGH",
        "outputId": "fb780169-5ed6-400f-a7b5-e9dffc8f93cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [01:10<00:00,  2.02s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr\n",
        "\n",
        "print(pearsonr(result, trial[:35][\"complexity\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzhhnWWqDLRJ",
        "outputId": "91fdf4c8-e069-4925-a9ef-470c9dc8250a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PearsonRResult(statistic=0.34661307567519706, pvalue=0.041366133598564)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the model\n",
        "generation_config = {\n",
        "  \"temperature\": 0.0,\n",
        "  \"top_p\": 0.6,\n",
        "  \"top_k\": 1,\n",
        "  \"max_output_tokens\": 100,\n",
        "}\n",
        "\n",
        "\n",
        "safe = [\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_DANGEROUS\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "    ]\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.0-pro-latest\",\n",
        "                              generation_config=generation_config, safety_settings = safe)\n",
        "\n",
        "result = []\n",
        "\n",
        "for row in tqdm(data):\n",
        "\n",
        "  prompt_parts = [\n",
        "    \"Sentence: He who receives a prophet in the name of a prophet will receive a prophet's reward. \"\\\n",
        "    \"Token: name \"\\\n",
        "    \"Lexical complexity score of token: 0.04999999999999999 \"\\\n",
        "    \"Sentence: Jesus said, 'Father, forgive them, for they don't know what they are doing.' \"\\\n",
        "    \"Token: Father \"\\\n",
        "    \"Lexical complexity score of token: 0.13333333333333336 \"\\\n",
        "    \"Sentence: Seven days you shall eat unleavened bread, as I commanded you, at the time appointed in the month Abib; for in the month Abib you came out from Egypt. \"\\\n",
        "    \"Token: days \"\\\n",
        "    \"Lexical complexity score of token: 0.25 \"\\\n",
        "    \"Sentence: Moreover Yahweh will deliver Israel also with you into the hand of the Philistines; and tomorrow you and your sons will be with me. \"\\\n",
        "    \"Token: sons \"\\\n",
        "    \"Lexical complexity score of token: 0.1607142857142857  \"\\\n",
        "    f\"Sentence: {row['sentence']} \" \\\n",
        "    f\"Token: {row['token']} \"\\\n",
        "    \"Lexical complexity score of token: \"\\\n",
        "\n",
        "    \"Learn from these examples and use all features you need, output one single number\"\n",
        "  ]\n",
        "  response = model.generate_content(prompt_parts)\n",
        "  # print(response.text)\n",
        "  result.append(float(response.text))"
      ],
      "metadata": {
        "id": "L3r4X4a_EdFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# result without the first example\n",
        "\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "print(pearsonr(result, trial[:35][\"complexity\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9fUh5GFEhab",
        "outputId": "bc188bfb-5ebe-44ce-c456-ff34e76b78b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PearsonRResult(statistic=0.0987088576971457, pvalue=0.5726575140355485)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the model\n",
        "generation_config = {\n",
        "  \"temperature\": 0.1,\n",
        "  \"top_p\": 0.6,\n",
        "  \"top_k\": 1,\n",
        "  \"max_output_tokens\": 100,\n",
        "}\n",
        "\n",
        "\n",
        "safe = [\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_DANGEROUS\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "    ]\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.0-pro-latest\",\n",
        "                              generation_config=generation_config, safety_settings = safe)\n",
        "\n",
        "n = 2\n",
        "\n",
        "result = []\n",
        "\n",
        "for row in tqdm(data):\n",
        "    for _ in range(n):\n",
        "        prompt_parts = [\n",
        "            \"Sentence: Behold, there came up out of the river seven cattle, sleek and fat, and they fed in the marsh grass. \"\\\n",
        "            \"Token: river \"\\\n",
        "            \"Lexical complexity score of token: 0.0 \"\\\n",
        "            \"Sentence: He who receives a prophet in the name of a prophet will receive a prophet's reward. \"\\\n",
        "            \"Token: name \"\\\n",
        "            \"Lexical complexity score of token: 0.04999999999999999 \"\\\n",
        "            \"Sentence: Jesus said, 'Father, forgive them, for they don't know what they are doing.' \"\\\n",
        "            \"Token: Father \"\\\n",
        "            \"Lexical complexity score of token: 0.13333333333333336 \"\\\n",
        "            \"Sentence: Seven days you shall eat unleavened bread, as I commanded you, at the time appointed in the month Abib; for in the month Abib you came out from Egypt. \"\\\n",
        "            \"Token: days \"\\\n",
        "            \"Lexical complexity score of token: 0.25 \"\\\n",
        "            \"Sentence: Moreover Yahweh will deliver Israel also with you into the hand of the Philistines; and tomorrow you and your sons will be with me. \"\\\n",
        "            \"Token: sons \"\\\n",
        "            \"Lexical complexity score of token: 0.1607142857142857  \"\\\n",
        "            f\"Sentence: {row['sentence']} \" \\\n",
        "            f\"Token: {row['token']} \"\\\n",
        "            \"Lexical complexity score of token: \"\\\n",
        "            \"Learn from these examples and use all features you need, output one single number\"\n",
        "        ]\n",
        "        # Call the model to generate a response\n",
        "        response = model.generate_content(prompt_parts)\n",
        "        # Append the generated number to the result list\n",
        "        result.append(float(response.text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "ol64vfb4HMdz",
        "outputId": "d1a913fb-83a6-4e93-d592-05ff0babfd77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [02:02<00:00,  3.51s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp = []\n",
        "for i in range(0, len(result), 2):\n",
        "  temp.append(np.mean(result[i : i +  2]))"
      ],
      "metadata": {
        "id": "gu1-F0duPT-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr\n",
        "\n",
        "print(pearsonr(temp, trial[:35][\"complexity\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOsncj_BNHNm",
        "outputId": "1b0e1cf1-bd8a-4b48-c0aa-4a8de4cc4b52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PearsonRResult(statistic=0.2955443120841459, pvalue=0.08476083567904134)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the model\n",
        "generation_config = {\n",
        "  \"temperature\": 0.1,\n",
        "  \"top_p\": 0.6,\n",
        "  \"top_k\": 1,\n",
        "  \"max_output_tokens\": 100,\n",
        "}\n",
        "\n",
        "\n",
        "safe = [\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_DANGEROUS\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "    ]\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.0-pro-latest\",\n",
        "                              generation_config=generation_config, safety_settings = safe)\n",
        "\n",
        "n = 10\n",
        "\n",
        "result = []\n",
        "for row in tqdm(data):\n",
        "    for _ in range(n):\n",
        "        prompt_parts = [\n",
        "            \"Sentence: Behold, there came up out of the river seven cattle, sleek and fat, and they fed in the marsh grass. \"\\\n",
        "            \"Token: river \"\\\n",
        "            \"Lexical complexity score of token: 0.0 \"\\\n",
        "            \"Sentence: He who receives a prophet in the name of a prophet will receive a prophet's reward. \"\\\n",
        "            \"Token: name \"\\\n",
        "            \"Lexical complexity score of token: 0.04999999999999999 \"\\\n",
        "            \"Sentence: Jesus said, 'Father, forgive them, for they don't know what they are doing.' \"\\\n",
        "            \"Token: Father \"\\\n",
        "            \"Lexical complexity score of token: 0.13333333333333336 \"\\\n",
        "            \"Sentence: Seven days you shall eat unleavened bread, as I commanded you, at the time appointed in the month Abib; for in the month Abib you came out from Egypt. \"\\\n",
        "            \"Token: days \"\\\n",
        "            \"Lexical complexity score of token: 0.25 \"\\\n",
        "            \"Sentence: Moreover Yahweh will deliver Israel also with you into the hand of the Philistines; and tomorrow you and your sons will be with me. \"\\\n",
        "            \"Token: sons \"\\\n",
        "            \"Lexical complexity score of token: 0.1607142857142857  \"\\\n",
        "            f\"Sentence: {row['sentence']} \" \\\n",
        "            f\"Token: {row['token']} \"\\\n",
        "            \"Lexical complexity score of token: \"\\\n",
        "            \"Learn from these examples and use all features you need, output one single number\"\n",
        "        ]\n",
        "        # Call the model to generate a response\n",
        "        response = model.generate_content(prompt_parts)\n",
        "        # Append the generated number to the result list\n",
        "        result.append(float(response.text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "FZxUoL6OTAXA",
        "outputId": "8e11be86-5d09-4bad-8a6a-481c0a9ccb31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [14:04<00:00, 24.14s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp = []\n",
        "for i in range(0, len(result), 10):\n",
        "  temp.append(np.mean(result[i : i +  10]))"
      ],
      "metadata": {
        "id": "CMNcNQ1QTEv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr\n",
        "\n",
        "print(pearsonr(temp, trial[:35][\"complexity\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcjrYAZUTH4J",
        "outputId": "46300457-29ad-44f7-a785-508cc254d0c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PearsonRResult(statistic=0.31383902844880485, pvalue=0.06636317976298513)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the model\n",
        "generation_config = {\n",
        "  \"temperature\": 0.0,\n",
        "  \"top_p\": 0.6,\n",
        "  \"top_k\": 1,\n",
        "  \"max_output_tokens\": 100,\n",
        "}\n",
        "\n",
        "\n",
        "safe = [\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_DANGEROUS\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "    ]\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.0-pro-latest\",\n",
        "                              generation_config=generation_config, safety_settings = safe)\n",
        "\n",
        "result = []\n",
        "\n",
        "for row in tqdm(data):\n",
        "\n",
        "  prompt_parts = [\n",
        "    \"Sentence: Behold, there came up out of the river seven cattle, sleek and fat, and they fed in the marsh grass. \"\\\n",
        "    \"Token: river \"\\\n",
        "    \"Lexical complexity score of token: 0.0 \"\\\n",
        "    \"Sentence: He who receives a prophet in the name of a prophet will receive a prophet's reward. \"\\\n",
        "    \"Token: name \"\\\n",
        "    \"Lexical complexity score of token: 0.04999999999999999 \"\\\n",
        "    \"Sentence: Jesus said, 'Father, forgive them, for they don't know what they are doing.' \"\\\n",
        "    \"Token: Father \"\\\n",
        "    \"Lexical complexity score of token: 0.13333333333333336 \"\\\n",
        "    \"Sentence: Seven days you shall eat unleavened bread, as I commanded you, at the time appointed in the month Abib; for in the month Abib you came out from Egypt. \"\\\n",
        "    \"Token: days \"\\\n",
        "    \"Lexical complexity score of token: 0.25 \"\\\n",
        "    f\"Sentence: {row['sentence']} \" \\\n",
        "    f\"Token: {row['token']} \"\\\n",
        "    \"Lexical complexity score of token: \"\n",
        "  ]\n",
        "  response = model.generate_content(prompt_parts)\n",
        "  # print(response.text)\n",
        "  result.append(float(response.text))"
      ],
      "metadata": {
        "id": "9hRLs09iCXQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr\n",
        "\n",
        "print(pearsonr(result, trial[:35][\"complexity\"]))"
      ],
      "metadata": {
        "id": "PcHIO5FtDsE6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}