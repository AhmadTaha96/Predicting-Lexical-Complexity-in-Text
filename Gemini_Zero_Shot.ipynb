{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3lKRPA5gxAZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3079f15a-962f-4edb-9212-dfdff9a3f274"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/145.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m122.9/145.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.9/145.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install google-generativeai==0.3.0\n",
        "!pip -q install google-ai-generativelanguage==0.4.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "# !pip install datasets --quiet\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import pearsonr\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "meRdjCoGjokC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O train.tsv \"https://raw.githubusercontent.com/neilrs123/Lexical-Complexity-Prediction/master/Dataset/Sub-task%201/lcp_single_train.tsv\"\n",
        "\n",
        "!wget -O trial.tsv \"https://raw.githubusercontent.com/neilrs123/Lexical-Complexity-Prediction/master/Dataset/Sub-task%201/lcp_single_trial.tsv\""
      ],
      "metadata": {
        "id": "Ov3ah58hjtl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, trial = df = pd.read_table('train.tsv'), pd.read_table('trial.tsv')\n",
        "\n",
        "train = train[train[\"corpus\"] == \"bible\"].drop([\"corpus\", \"id\"], axis = 1)\n",
        "trial = trial[trial[\"subcorpus\"] == \"bible\"].drop([\"subcorpus\", \"id\"], axis = 1)"
      ],
      "metadata": {
        "id": "AxneTmknjwcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "kIMeQFxQhEBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "GOOGLE_AI_STUDIO = userdata.get('key')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_AI_STUDIO)"
      ],
      "metadata": {
        "id": "HVJCEfpOhMtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "    print(m.name)\n",
        "    print(m.supported_generation_methods)"
      ],
      "metadata": {
        "id": "YGR33ka4hRt6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "6941252c-5e36-436c-93f8-d24cb7d87842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/chat-bison-001\n",
            "['generateMessage', 'countMessageTokens']\n",
            "models/text-bison-001\n",
            "['generateText', 'countTextTokens', 'createTunedTextModel']\n",
            "models/embedding-gecko-001\n",
            "['embedText', 'countTextTokens']\n",
            "models/gemini-1.0-pro\n",
            "['generateContent', 'countTokens']\n",
            "models/gemini-1.0-pro-001\n",
            "['generateContent', 'countTokens', 'createTunedModel']\n",
            "models/gemini-1.0-pro-latest\n",
            "['generateContent', 'countTokens']\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "['generateContent', 'countTokens']\n",
            "models/gemini-1.5-pro-latest\n",
            "['generateContent', 'countTokens']\n",
            "models/gemini-pro\n",
            "['generateContent', 'countTokens']\n",
            "models/gemini-pro-vision\n",
            "['generateContent', 'countTokens']\n",
            "models/embedding-001\n",
            "['embedContent']\n",
            "models/text-embedding-004\n",
            "['embedContent']\n",
            "models/aqa\n",
            "['generateAnswer']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets --quiet\n",
        "from datasets import Dataset\n",
        "\n",
        "data = Dataset.from_pandas(trial[:35])"
      ],
      "metadata": {
        "id": "ktyqKrsRkMVr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28e18bf3-e9c6-47ed-f8dd-726a6100085c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the model\n",
        "generation_config = {\n",
        "  \"temperature\": 0.1,\n",
        "  \"top_p\": 0.6,\n",
        "  \"top_k\": 1,\n",
        "  \"max_output_tokens\": 100,\n",
        "}\n",
        "\n",
        "\n",
        "safe = [\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_DANGEROUS\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "    ]\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.0-pro-latest\",\n",
        "                              generation_config=generation_config, safety_settings = safe)\n",
        "\n",
        "result = []\n",
        "\n",
        "for row in tqdm(data):\n",
        "\n",
        "  prompt_parts = [\n",
        "    \"Evaluate the lexical complexity of the token by considering its interaction and relationship \" \\\n",
        "    \"with the other elements within the sentence. Reflect on how this token contributes to the overall \" \\\n",
        "    \"sentence meaning and structure. Provide a complexity score from 0 to 1, reflecting the lowest to \" \\\n",
        "    \"highest complexity, guided by the mean score of 0.301 and a standard deviation of 0.133.\\n\" \\\n",
        "    \"Output only one single score number\"\n",
        "    f\"\\nSentence: {row['sentence']}\" \\\n",
        "    f\"\\nToken: {row['token']}\"\n",
        "]\n",
        "\n",
        "  response = model.generate_content(prompt_parts)\n",
        "  # print(response.text)\n",
        "  result.append(float(response.text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "NE5PnYbiha7T",
        "outputId": "baaa5db3-5268-47af-956e-36c90e0ea712"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [01:09<00:00,  1.98s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr\n",
        "\n",
        "print(pearsonr(result, trial[:35][\"complexity\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXaAmP36goOO",
        "outputId": "467be6b3-efac-4881-a0a8-6a648f4c6d83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PearsonRResult(statistic=0.41062403253124125, pvalue=0.014277201494427804)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr\n",
        "\n",
        "# on seed = 9, temperature = 0.1, top_p = 0.5, top_k = 1\n",
        "print(pearsonr(result, trial[:35][\"complexity\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SG6kG0MwlITn",
        "outputId": "31809491-f839-40ed-dbcd-4363c44ba964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PearsonRResult(statistic=0.4109067400673655, pvalue=0.0142038747685761)\n"
          ]
        }
      ]
    }
  ]
}